# VolAlign Pipeline Configuration Template
# This file contains all configurable parameters for the microscopy processing pipeline
# Modify these values according to your specific dataset and processing requirements

# Working directory for all pipeline outputs
working_directory: "./pipeline_output"

# Voxel spacing in micrometers [z, y, x]
# Adjust these values based on your microscope settings
voxel_spacing: [0.2, 0.1625, 0.1625]

# Downsample factors for efficient processing [z, y, x]
# Higher values = faster processing but lower resolution
# Separate factors for different pipeline tasks
downsample_factors:
  # Used for registration tasks (affine alignment)
  # Can be more aggressive since registration is robust to lower resolution
  registration: [4, 7, 7]
  
  # Used for segmentation tasks (nuclei detection)
  # Should be more conservative to preserve fine details needed for accurate segmentation
  segmentation: [1, 3, 3]

# Block size for distributed processing [z, y, x]
# Adjust based on available memory and data size
block_size: [512, 512, 512]

# Multi-round data configuration
data:
  # Reference round name - this round will be used as the fixed reference for all alignments
  # and will be the source for segmentation
  reference_round: "round1"
  
  # Data paths for each imaging round
  # Each round should contain the same channel names
  rounds:
    round1:
      "405": "/path/to/round1_405nm.tif"
      "488": "/path/to/round1_488nm.tif"
      "channel3": "/path/to/round1_channel3.tif"
      "channel4": "/path/to/round1_channel4.tif"
    
    round2:
      "405": "/path/to/round2_405nm.tif"
      "488": "/path/to/round2_488nm.tif"
      "channel3": "/path/to/round2_channel3.tif"
      "channel4": "/path/to/round2_channel4.tif"
    
    round3:
      "405": "/path/to/round3_405nm.tif"
      "488": "/path/to/round3_488nm.tif"
      "channel3": "/path/to/round3_channel3.tif"
      "channel4": "/path/to/round3_channel4.tif"
    
    # Add more rounds as needed...
    # round4:
    #   "405": "/path/to/round4_405nm.tif"
    #   "488": "/path/to/round4_488nm.tif"
    #   "channel3": "/path/to/round4_channel3.tif"
    #   "channel4": "/path/to/round4_channel4.tif"

# Registration configuration
registration:
  # Strategy for merging channels: "mean", "max", or "stack"
  merge_strategy: "mean"
  
  # Channels to use for registration (typically DAPI channels)
  # First channel is used as reference for alignment
  channels: ["405", "488"]
  
  # Chunk alignment configuration for handling non-linear deformation
  # Use initial_chunk_alignment instead of initial_global_alignment
  # when your data has significant non-linear deformation
  chunk_alignment:
    # Downsampling factors for efficient processing [z, y, x]
    # Higher values = faster processing but lower resolution
    downsample_factors: [1, 3, 3]
    
    # Interpolation method for deformation field upsampling
    # Options: "linear", "bspline", "cubic"
    interpolation_method: "linear"
    
    # Block size for distributed processing [z, y, x]
    # Should match or be smaller than main block_size
    block_size: [512, 512, 512]
    
    # Overlap fraction for distributed processing
    overlap: 0.3
    
    # Alignment parameters for chunk-based processing
    alignment_kwargs:
      # Blob sizes for feature detection [min_size, max_size]
      blob_sizes: [8, 200]
      # Use GPU acceleration if available
      use_gpu: true

# Segmentation configuration
segmentation:
  # Channel to use for nuclei segmentation (typically DAPI)
  channel: "405"
  
  # Whether to downsample data before segmentation for speed
  downsample_for_processing: true
  
  # Whether to upsample segmentation results back to original resolution
  upsample_results: true

# Distributed computing cluster configuration
cluster_config:
  # Cluster type: "local_cluster", "slurm_cluster", "pbs_cluster", etc.
  cluster_type: "local_cluster"
  
  # Number of worker processes
  n_workers: 8
  
  # Number of threads per worker
  threads_per_worker: 1
  
  # Memory limit per worker (e.g., "150GB", "32GB")
  memory_limit: "150GB"
  
  # Additional cluster configuration options
  config:
    distributed.nanny.pre-spawn-environ:
      MALLOC_TRIM_THRESHOLD_: 65536
      MKL_NUM_THREADS: 10
      OMP_NUM_THREADS: 10
      OPENBLAS_NUM_THREADS: 10
    distributed.scheduler.worker-ttl: null

# Segmentation-specific cluster configuration
# Optimized for GPU-based segmentation tasks with higher memory requirements
segmentation_cluster_config:
  # Number of worker processes (fewer workers for GPU tasks)
  n_workers: 3
  
  # Number of threads per worker
  threads_per_worker: 1
  
  # Memory limit per worker (higher for segmentation tasks)
  memory_limit: "300GB"
  
  # Use local CUDA for GPU processing
  use_local_cuda: true
  
