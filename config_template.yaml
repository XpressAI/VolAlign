# VolAlign Pipeline Configuration Template
# This file contains all configurable parameters for the microscopy processing pipeline
# Modify these values according to your specific dataset and processing requirements

# Working directory for all pipeline outputs
working_directory: "./pipeline_output"

# Voxel spacing in micrometers [z, y, x]
# Adjust these values based on your microscope settings
voxel_spacing: [0.2, 0.1625, 0.1625]

# Downsample factors for efficient processing [z, y, x]
# Higher values = faster processing but lower resolution
# Separate factors for different pipeline tasks
downsample_factors:
  # Used for registration tasks (affine alignment)
  # Can be more aggressive since registration is robust to lower resolution
  registration: [4, 7, 7]
  
  # Used for segmentation tasks (nuclei detection)
  # Should be more conservative to preserve fine details needed for accurate segmentation
  segmentation: [1, 3, 3]

# Block size for distributed processing [z, y, x]
# Adjust based on available memory and data size
block_size: [512, 512, 512]

# Multi-round data configuration
data:
  # Reference round name - this round will be used as the fixed reference for all alignments
  # and will be the source for segmentation
  reference_round: "round1"
  
  # Data paths for each imaging round
  # Each round should contain the same channel names
  rounds:
    round1:
      "405": "/path/to/round1_405nm.tif"
      "488": "/path/to/round1_488nm.tif"
      "546": "/path/to/round1_546nm.tif"
      "647": "/path/to/round1_647nm.tif"
    
    round2:
      "405": "/path/to/round2_405nm.tif"
      "488": "/path/to/round2_488nm.tif"
      "546": "/path/to/round2_546nm.tif"
      "647": "/path/to/round2_647nm.tif"
    
    round3:
      "405": "/path/to/round3_405nm.tif"
      "488": "/path/to/round3_488nm.tif"
      "546": "/path/to/round3_546nm.tif"
      "647": "/path/to/round3_647nm.tif"
    
    # Add more rounds as needed...
    # round4:
    #   "405": "/path/to/round4_405nm.tif"
    #   "488": "/path/to/round4_488nm.tif"
    #   "546": "/path/to/round4_546nm.tif"
    #   "647": "/path/to/round4_647nm.tif"

# Registration configuration
registration:
  # Strategy for merging channels: "mean", "max", or "stack"
  merge_strategy: "mean"
  
  # Channels to use for registration (typically DAPI channels)
  # First channel is used as reference for alignment, you can use up to two reference channels
  channels: ["405"]
  
  # Chunk alignment configuration for handling non-linear deformation
  # Use initial_chunk_alignment instead of initial_global_alignment
  # when your data has significant non-linear deformation
  chunk_alignment:
    # Downsampling factors for efficient processing [z, y, x]
    # Higher values = faster processing but lower resolution
    downsample_factors: [1, 3, 3]
    
    # Interpolation method for deformation field upsampling
    # Options: "linear", "bspline", "cubic"
    interpolation_method: "linear"
    
    # Block size for distributed processing [z, y, x]
    # Should match or be smaller than main block_size
    block_size: [512, 512, 512]
    
    # Overlap fraction for distributed processing
    overlap: 0.3
    
    # Alignment parameters for chunk-based processing
    alignment_kwargs:
      # Blob sizes for feature detection [min_size, max_size]
      blob_sizes: [8, 200]
      # Use GPU acceleration if available
      use_gpu: true

# Segmentation configuration
segmentation:
  # Channel to use for nuclei segmentation (typically DAPI)
  channel: "405"
  
  # Whether to downsample data before segmentation for speed
  downsample_for_processing: true
  
  # Whether to upsample segmentation results back to original resolution
  upsample_results: true

# Distributed computing cluster configuration
cluster_config:
  # Cluster type: "local_cluster", "slurm_cluster", "pbs_cluster", etc.
  cluster_type: "local_cluster"
  
  # Number of worker processes
  n_workers: 8
  
  # Number of threads per worker
  threads_per_worker: 1
  
  # Memory limit per worker (e.g., "150GB", "32GB")
  memory_limit: "180GB"
  
  # Additional cluster configuration options
  config:
    distributed.nanny.pre-spawn-environ:
      MALLOC_TRIM_THRESHOLD_: 65536
      MKL_NUM_THREADS: 10
      OMP_NUM_THREADS: 10
      OPENBLAS_NUM_THREADS: 10
    distributed.scheduler.worker-ttl: null

# Segmentation-specific cluster configuration
# Optimized for GPU-based segmentation tasks with higher memory requirements
segmentation_cluster_config:
  # Number of worker processes (fewer workers for GPU tasks)
  n_workers: 3
  
  # Number of threads per worker
  threads_per_worker: 1
  
  # Memory limit per worker (higher for segmentation tasks)
  memory_limit: "300GB"
  
  # Use local CUDA for GPU processing
  use_local_cuda: true

# Epitope Analysis Configuration
epitope_analysis:
  # Whether to enable epitope analysis as part of the pipeline
  enabled: true
  
  # Shell region parameters for epitope analysis
  shell_parameters:
    # Number of erosion iterations to create inner boundary
    erosion_iterations: 2
    
    # Number of dilation iterations to create outer boundary
    dilation_iterations: 6
    
    # Size of morphological footprint (3D ball radius or 2D square size)
    footprint_size: 3
    
    # Whether to use 3D morphology (true) or 2D slice-by-slice (false)
    use_3d_morphology: false
  
  # Epitope channels configuration
  # Define which channels contain epitope markers across all rounds
  epitope_channels:
    # List of channel names that contain epitope markers
    channels: ["488", "546", "647"]
    
    # Optional tags for each channel (for better identification)
    channel_tags:
      "488": "Epitope_488nm"
      "546": "Epitope_546nm"
      "647": "Epitope_647nm"
  
  # Analysis parameters
  analysis_parameters:
    # Set to null to analyze ALL nuclei (no limit)
    max_nuclei_per_round: null
    
    # Default region for analysis: "nuclei", "shell", or "combined"
    default_region: "combined"
  
  # Statistical analysis configuration
  statistical_analysis:
    # Cutoff method: "otsu", "percentile", "gmm"
    cutoff_method: "otsu"
    
    # Random seed for reproducible results
    random_state: 42
  
  # Output configuration
  output:
    # Subdirectory name for epitope analysis results
    output_subdir: "epitope_analysis"
    
    # Output formats: ["json", "csv", "hdf5"]
    save_formats: ["json", "csv"]
    
    # Whether to save detailed statistical distributions
    save_detailed_stats: true

  
